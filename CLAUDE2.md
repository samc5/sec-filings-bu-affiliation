# Technical Specification for SEC EDGAR Biographical Search System

Instructions generated by Claude.AI to improve the code implementation to better match the results produced by Claude.AI itself.

Here's a comprehensive prompt you can give to Claude Code:

---

## Project Goal
Build a Python-based system to search SEC EDGAR filings for individuals affiliated with specific organizations (e.g., Boston University) by analyzing biographical information in corporate disclosures.

## Technical Requirements

### 1. SEC EDGAR API Integration
- Use the SEC EDGAR REST API (requires User-Agent header with your email)
- Implement proper rate limiting (10 requests/second max per SEC guidelines)
- Focus on filing types most likely to contain biographical data:
  - **DEF 14A** (Proxy Statements) - Primary source for director/executive bios
  - **10-K** (Annual Reports) - Management section
  - **8-K** (Current Reports) - Executive appointments (Item 5.02)
  - **S-1, S-4, 424B** (Registration Statements) - IPO/merger disclosures
  - **Form 4, Form 5** (Insider Trading) - For names to cross-reference

### 2. Document Processing Strategy

**Phase 1: Efficient Filtering**
- Query the SEC full-text search API: `https://efts.sec.gov/LATEST/search-index`
- Search for organization name (e.g., "Boston University") to get relevant CIK numbers and filing accessions
- Download only the filtered subset of documents
- Parse both HTML and SGML/XML formats

**Phase 2: Intelligent Extraction**
- Identify biographical sections using pattern recognition:
  - Look for headers: "Directors", "Executive Officers", "Management", "Biographical Information"
  - Find sections with education keywords: "degree", "graduated", "B.A.", "M.B.A.", "J.D.", "Ph.D."
  - Detect structured tables with Name/Age/Position/Background columns
- Extract person names using NLP (spaCy for named entity recognition)
- Extract surrounding context (Â±500 characters) around organization mentions

**Phase 3: Structured Data Extraction**
For each person found:
- Name
- Organization affiliation type (degree earned, year, faculty position, board membership, etc.)
- Current role/title
- Company/organization
- Filing metadata (type, date, CIK, accession number)

### 3. Implementation Architecture

```python
# Key components:

1. SECClient class
   - Handle API authentication and rate limiting
   - Implement exponential backoff for errors
   - Cache downloaded filings locally

2. FilingParser class
   - Parse HTML/SGML formats
   - Use BeautifulSoup4 for HTML parsing
   - Extract text from complex nested tables

3. BiographyExtractor class
   - Use regex + spaCy NER for name extraction
   - Context window analysis for affiliation details
   - Fuzzy matching for organization name variations
   - Extract degree types, years, positions

4. DataAggregator class
   - Deduplicate individuals found in multiple filings
   - Merge information across filing types
   - Export to CSV/JSON with proper citations
```

### 4. Key Technical Challenges & Solutions

**Challenge: HTML Structure Variability**
- Solution: Use multiple parsing strategies (CSS selectors, regex, table detection)
- Implement fallback methods if primary parsing fails

**Challenge: Organization Name Variations**
- Solution: Build fuzzy matching (e.g., "BU", "Boston U.", "Boston University School of Law")
- Use regex patterns for common abbreviations

**Challenge: Scale (millions of filings)**
- Solution: 
  - Start with full-text search API to filter
  - Process most recent filings first (last 5-10 years)
  - Implement parallel processing with proper rate limiting
  - Use SQLite database for caching and deduplication

**Challenge: Biographical Context Understanding**
- Solution:
  - Use spaCy's dependency parsing to understand sentence structure
  - Look for education-specific patterns: "[Degree] from [University]"
  - Detect time indicators (graduation years, employment dates)

### 5. Libraries & Dependencies

```
Required:
- requests (SEC API calls)
- beautifulsoup4 + lxml (HTML parsing)
- spacy + en_core_web_sm model (NER and text analysis)
- pandas (data manipulation)
- sqlite3 (caching, built-in)
- ratelimit (API throttling)
- python-dotenv (config management)

Optional but recommended:
- tenacity (retry logic)
- tqdm (progress bars)
- pdfplumber (if processing PDF exhibits)
```

### 6. Deliverables

1. Command-line tool with arguments:
   ```
   python edgar_bio_search.py --org "Boston University" --years 5 --output results.csv
   ```

2. Output CSV with columns:
   - Name
   - Organization_Affiliation
   - Affiliation_Type (Degree/Faculty/Board/Other)
   - Degree_Year (if applicable)
   - Current_Role
   - Company
   - Filing_Type
   - Filing_Date
   - Filing_URL

3. Summary statistics report
4. Logging system for debugging

### 7. Development Approach

**Start simple, iterate:**
1. Build SEC API client with single filing download
2. Parse one DEF 14A successfully 
3. Extract biographical info from that one document
4. Scale to multiple documents
5. Add full-text search filtering
6. Optimize for performance
7. Add comprehensive error handling

### 8. Testing Strategy

Test on known examples:
- Find a recent DEF 14A with known Boston University affiliations
- Verify extraction accuracy
- Test edge cases (name variations, multiple degrees, faculty positions)

### 9. Compliance & Best Practices

- Respect SEC fair access policy (rate limits)
- Include proper User-Agent header
- Cache documents locally to avoid redundant downloads
- Document all data sources with filing URLs
- Handle PII responsibly

---

## Starting Implementation Hints

1. **First API call to try:**
```python
import requests
headers = {'User-Agent': 'YourName yourname@email.com'}
search_url = 'https://efts.sec.gov/LATEST/search-index'
params = {
    'q': '"Boston University"',
    'dateRange': 'custom',
    'category': 'custom',
    'forms': ['DEF 14A', '10-K', '8-K']
}
```

2. **Biography section detection patterns:**
```python
bio_headers = [
    r'biographical?\s+information',
    r'executive\s+officers?',
    r'directors?\s+and\s+executive',
    r'board\s+of\s+directors?',
    r'management\s+team'
]
```

3. **Education extraction regex:**
```python
education_pattern = r'(B\.?A\.?|B\.?S\.?|M\.?B\.?A\.?|M\.?S\.?|J\.?D\.?|Ph\.?D\.?|LL\.?M\.?)[,\s]+.*?(?:from|at)\s+([A-Z][^,\.;]+(?:University|College|Institute))'
```

This gives Claude Code a clear roadmap to build an effective system using only public APIs and standard techniques. The key is systematic processing, intelligent parsing, and proper engineering practices rather than proprietary database access.